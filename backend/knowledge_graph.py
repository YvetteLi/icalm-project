from altair import selection

from backend.kg_building_util import *
from backend.functionality_util import toml_load, run_query
from langchain.schema import Document
from neo4j_config.config import graph
from langchain_config.config import embedding_model
import logging
from langchain_community.graphs.graph_document import GraphDocument

# Setting up path for examples
EXAMPLE_PATH = 'assets/examples/example.toml'

def get_node_embeddings(text: str):
    """
    Generates embeddings for a given text using the OpenAI Embeddings API.

    Parameters:
    text (str): The text for which embeddings need to be generated.

    Returns:
    list: A list of embeddings generated by the API for the input text.
    """
    # Generate embeddings for the node using the OpenAI Embeddings API
    return embedding_model.embed_query(text)


def extract_and_store_graph(
        document: Document,
        topic,
        first_time_load=True
) -> None:
    """
    Extracts graph data from the provided document and stores the results in a graph database.

    Arguments:
    document: Document
        An instance of the Document class containing the content from which the graph data will be extracted.
    topic: str
        The topic key used to retrieve example and result configurations from the example file.
    first_time_load: bool, optional, default=True
        Flag to indicate if this is the first time loading data into the graph. If True, existing nodes in the graph will be deleted before adding the new data.

    Procedure:
    1. Loads example configurations from a TOML file using the provided topic key.
    2. Extracts graph data using OpenAI functions and invokes the extraction chain on the document's content.
    3. Filters out nodes where both the question and the answer are missing.
    4. Embeds nodes with text properties using a node embedding function.
    5. Constructs a new graph document with nodes containing embeddings and their corresponding relationships.
    6. If first_time_load is True, deletes all existing nodes in the graph before adding the new graph document.
    """
    example_file = toml_load(EXAMPLE_PATH)
    # selected_example = example_file.get(topic, '')
    selected_example = example_file.get(topic, {})
    example = selected_example.get('example', '' )
    results = selected_example.get('results', '')

    # Extract graph data using OpenAI functions
    extract_chain = get_extraction_chain(example, results)
    logging.warning(extract_chain)

    data = extract_chain.invoke(document.page_content)['function']

    # Filter out nodes where both question and answer do not exist
    filtered_nodes = []
    for node in data.nodes:
        # Check if question or answer exists
        has_question = len(node.properties) > 0 and node.properties[0].value
        has_answer = len(node.properties) > 1 and node.properties[1].value

        if has_question or has_answer:
            # If at least one exists, keep the node
            node_text = ""
            if has_question:
                node_text += "question: " + node.properties[0].value
            if has_answer:
                node_text += " answer: " + node.properties[1].value

            # Get the node embedding
            embedding = get_node_embeddings(node_text)

            # Store the node with its embedding
            node.properties.append(Property(key='embedding', value=embedding))
            filtered_nodes.append(node)

    # Update the nodes with the filtered list
    data.nodes = filtered_nodes

    # Construct a graph document with the nodes containing embeddings
    graph_document = GraphDocument(
        nodes=[map_to_base_node(node) for node in data.nodes],
        relationships=[map_to_base_relationship(rel) for rel in data.rels],
        source=document
    )
    if first_time_load:
        graph.query("MATCH (n) DETACH DELETE n")
    graph.add_graph_documents([graph_document])
